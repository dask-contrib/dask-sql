properties:

  sql:
    type: object
    properties:

      aggregate:
        type: object
        properties:

          split_out:
            type: integer
            description: |
              Number of output partitions from an aggregation operation

          split_every:
            type: [integer, "null"]
            description: |
              Number of branches per reduction step from an aggregation operation.

      identifier:
        type: object
        properties:

          case_sensitive:
            type: boolean
            description: |
              Whether sql identifiers are considered case sensitive while parsing.

      join:
        type: object
        properties:

          broadcast:
            type: [boolean, number, "null"]
            description: |
              If boolean, it determines whether all joins should use the broadcast join algorithm.
              If float, it's a value denoting dask's likelihood of selecting a broadcast join based
              codepath over a shuffle based join. Concretely, dask will select a broadcast based join
              algorithm if small_table.npartitions < log2(big_table.npartitions) * broadcast_bias
              Note: Forcing a broadcast join might lead to perf issues or OOM errors in cases where the
              broadcasted table is too large to fit on a single worker.

      limit:
        type: object
        properties:

          check-first-partition:
            type: boolean
            description: |
              Whether or not to check the first partition length when computing a LIMIT without an OFFSET
              on a table with a relatively simple Dask graph (i.e. only IO and/or partition-wise layers);
              checking partition length triggers a Dask graph computation which can be slow for complex
              queries, but can signicantly reduce memory usage when querying a small subset of a large
              table. Default is ``true``.

      optimize:
        type: boolean
        description: |
          Whether the first generated logical plan should be further optimized or used as is.

      predicate_pushdown:
        type: boolean
        description: |
          Whether to try pushing down filter predicates into IO (when possible).

      dynamic_partition_pruning:
        type: boolean
        description: |
          Whether to apply the dynamic partition pruning optimizer rule.

      optimizer:
        type: object
        properties:

          verbose:
            type: boolean
            description: |
              The dynamic partition pruning optimizer rule can sometimes result in extremely long
              c.explain() outputs which are not helpful to the user. Setting this option to true
              allows the user to see the entire output, while setting it to false truncates the
              output. Default is false.

      fact_dimension_ratio:
        type: [number, "null"]
        description: |
          Ratio of the size of the dimension tables to fact tables. Parameter for dynamic partition
          pruning and join reorder optimizer rules.

      max_fact_tables:
        type: [integer, "null"]
        description: |
          Maximum number of fact tables to allow in a join. Parameter for join reorder optimizer
          rule.

      preserve_user_order:
        type: [boolean, "null"]
        description: |
          Whether to preserve user-defined order of unfiltered dimensions. Parameter for join
          reorder optimizer rule.

      filter_selectivity:
        type: [number, "null"]
        description: |
          Constant to use when determining the number of rows produced by a filtered relation.
          Parameter for join reorder optimizer rule.

      sort:
        type: object
        properties:

          topk-nelem-limit:
            type: integer
            description: |
              Total number of elements below which dask-sql should attempt to apply the top-k
              optimization (when possible). ``nelem`` is defined as the limit or ``k`` value times the
              number of columns. Default is 1000000, corresponding to a LIMIT clause of 1 million in a
              1 column table.

      mappings:
        type: object
        properties:

          decimal_support:
            type: string
            description:
              Decides how to handle decimal scalars/columns. ``"pandas"`` handling will treat decimals scalars and columns as floats and float64 columns, respectively, while ``"cudf"`` handling treats decimal scalars as ``decimal.Decimal`` objects and decimal columns as ``cudf.Decimal128Dtype`` columns, handling precision/scale accordingly. Default is ``"pandas"``, but ``"cudf"`` should be used if attempting to work with decimal columns on GPU.
